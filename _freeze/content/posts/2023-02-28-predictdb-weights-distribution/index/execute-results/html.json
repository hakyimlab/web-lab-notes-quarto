{
  "hash": "e136f6204264490020b5d6fd0b290041",
  "result": {
    "markdown": "---\ntitle: \"PredictDB weight distribution\"\nauthor: \"Haky Im\"\ndate: \"2023-02-28\"\ncategories: [analysis]\nformat:\n  html:\n    code-fold: true\n    code-summary: \"Show the code\"\neditor_options: \n  chunk_output_type: console\n---\n\n\nGoal: get effect size distribution of omic traits\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressMessages(library(tidyverse))\nsuppressMessages(library(glue))\nPRE = \"/Users/haekyungim/Library/CloudStorage/Box-Box/LargeFiles/imlab-data/data-Github/web-data\"\n##PRE=\"/Users/margaretperry/Library/CloudStorage/Box-Box/imlab-data/data-Github/web-data \"\n##PRE=\"/Users/temi/Library/CloudStorage/Box-Box/imlab-data/data-Github/web-data\"\n## COPY THE DATE AND SLUG fields FROM THE HEADER\nSLUG=\"predictdb-weight-distribution\" ## copy the slug from the header\nbDATE='2023-02-28' ## copy the date from the blog's header here\nDATA = glue(\"{PRE}/{bDATE}-{SLUG}\")\nif(!file.exists(DATA)) system(glue::glue(\"mkdir {DATA}\"))\nWORK=DATA\nUSERNAME=\"haekyungim\"\n## move data to DATA\n#tempodata=(\"~/Downloads/tempo/gwas_catalog_v1.0.2-associations_e105_r2022-04-07.tsv\")\n#system(glue::glue(\"cp {tempodata} {DATA}/\"))\n## system(glue(\"open {DATA}\")) ## this will open the folder \n```\n:::\n\n\n-   [ ] download mashr gtex v8 prediction models for various\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif(F)\n{\n  setwd(DATA)\n  system(glue(\"wget https://zenodo.org/record/3518299/files/mashr_eqtl.tar?download=1\"))\n  system(glue(\"tar xvf mashr_eqtl.tar\"))\n  system(glue(\"cd eqtl\"))\n  system(\"rm *.txt.gz\")\n}\n```\n:::\n\n\n-   [ ] plot distribution, show summary\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"RSQLite\")\nsqlite <- dbDriver(\"SQLite\")\n\nmyshowdist = function(dbname,titulo=\"n=\")\n{\nprint(dbname)\ndb = dbConnect(sqlite,dbname)\nweights = dbGetQuery(db, \"select * from weights\")\nabsweivec = abs(weights$weight)\nqlines = quantile(absweivec,c(0.2,0.5)) %>% round(2)\nquantile(absweivec,(0:10)/10) %>% round(2) %>% print()\npp <- weights %>% mutate(abswei=abs(weight)) %>% ggplot(aes(abswei))+geom_histogram() + geom_vline(xintercept=qlines) +ggtitle(glue(\"{titulo}; 20%={qlines[1]}, median={qlines[2]}\"))\nprint(pp)\ndbDisconnect(db)\n}\n```\n:::\n\n\n-   [ ] read weights adipose with 491 samples\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbname <- glue(\"{DATA}/eqtl/mashr_Adipose_Subcutaneous.db\") ## add full path if db file not in current directory\nmyshowdist(dbname,titulo=\"Adipose expr n=491\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n/Users/haekyungim/Library/CloudStorage/Box-Box/LargeFiles/imlab-data/data-Github/web-data/2023-02-28-predictdb-weight-distribution/eqtl/mashr_Adipose_Subcutaneous.db\n  0%  10%  20%  30%  40%  50%  60%  70%  80%  90% 100% \n0.00 0.02 0.05 0.08 0.12 0.15 0.20 0.25 0.34 0.50 2.47 \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n-   [ ] read weights brain substantia nigra with 101 samples\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbname <- glue(\"{DATA}/eqtl/mashr_Brain_Substantia_nigra.db\") ## add full path if db file not in current directory\nmyshowdist(dbname,titulo=\"Brain SN expr - n=101\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n/Users/haekyungim/Library/CloudStorage/Box-Box/LargeFiles/imlab-data/data-Github/web-data/2023-02-28-predictdb-weight-distribution/eqtl/mashr_Brain_Substantia_nigra.db\n  0%  10%  20%  30%  40%  50%  60%  70%  80%  90% 100% \n0.00 0.01 0.02 0.04 0.07 0.10 0.14 0.20 0.29 0.44 2.56 \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n-   [ ] read protein prediction weights\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## can download from https://uchicago.box.com/shared/static/m3zsxy3oy8kn5gkktkuo8lvui269hxi5.db\nprint(\"AA\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AA\"\n```\n:::\n\n```{.r .cell-code}\ndbname <- glue::glue(\"/Users/{USERNAME}/Library/CloudStorage/Box-Box/LargeFiles/imlab-data/Within-Lab-Sharing/Sabrina-Data/ARIC/ARIC_AA_hg38.db\")\nmyshowdist(dbname,titulo=\"protein ARIC AA n=1,871\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n/Users/haekyungim/Library/CloudStorage/Box-Box/LargeFiles/imlab-data/Within-Lab-Sharing/Sabrina-Data/ARIC/ARIC_AA_hg38.db\n  0%  10%  20%  30%  40%  50%  60%  70%  80%  90% 100% \n0.00 0.00 0.00 0.00 0.00 0.01 0.01 0.01 0.02 0.03 0.59 \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n## can download from https://uchicago.box.com/shared/static/m3zsxy3oy8kn5gkktkuo8lvui269hxi5.db\nprint(\"EUR\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"EUR\"\n```\n:::\n\n```{.r .cell-code}\ndbname <- glue::glue(\"/Users/{USERNAME}/Library/CloudStorage/Box-Box/LargeFiles/imlab-data/Within-Lab-Sharing/Sabrina-Data/ARIC/ARIC_EA_hg38.db\")\nmyshowdist(dbname,titulo=\"protein ARIC EA n=7,213\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n/Users/haekyungim/Library/CloudStorage/Box-Box/LargeFiles/imlab-data/Within-Lab-Sharing/Sabrina-Data/ARIC/ARIC_EA_hg38.db\n  0%  10%  20%  30%  40%  50%  60%  70%  80%  90% 100% \n0.00 0.00 0.00 0.00 0.00 0.01 0.01 0.01 0.01 0.03 0.55 \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n- [ ] read brainxcan weights (use elastic net to be closer to QTL effect size)\n\n::: {.cell}\n\n```{.r .cell-code}\n##install.packages(\"arrow\")\ntempo = arrow::read_parquet(glue::glue(\"{DATA}/brainxcan-gw_lasso_beta.parquet\"))\ntempo = as.matrix(tempo %>% select(starts_with(\"IDP\")))\nkk = abs(tempo[tempo!=0])\nprint(summary(kk))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n0.0000000 0.0003630 0.0009091 0.0013655 0.0018487 0.0652540 \n```\n:::\n\n```{.r .cell-code}\nprint(quantile(kk,(0:10)/10))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          0%          10%          20%          30%          40%          50% \n1.513009e-11 1.207948e-04 2.761802e-04 4.559484e-04 6.659417e-04 9.090500e-04 \n         60%          70%          80%          90%         100% \n1.205991e-03 1.594788e-03 2.162211e-03 3.165862e-03 6.525400e-02 \n```\n:::\n\n```{.r .cell-code}\nprint(quantile(kk,c(0.2,0.5)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         20%          50% \n0.0002761802 0.0009090500 \n```\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}