{
  "hash": "8f00a66e2b6e76bd6af8e338a451a0f4",
  "result": {
    "markdown": "---\ntitle: \"Inflation Brainxcan\"\nauthor: \"Haky Im\"\ndate: \"2023-04-07\"\ncategories: [analysis]\neditor_options: \n  chunk_output_type: console\nformat:\n  html:\n    code-fold: false\n    code-summary: \"Show the code\"\n    code-tools: true\n    code-overflow: wrap\n---\n\n\n::: {.callout-tip}\n## Summary\nWhen both $Y$ and a mediator IDP are polygenic, the regression test $Y$ on IDP is inflated with $\\text{Var}(Z_\\text{bxcan}) = 1 + N h_1^2 \\cdot \\frac{\\text{tr}(R'R)}{\\text{tr}^2(R)}$. I'll use simulations to understand this relationship as functions of $h_Y$, $h_\\text{IDP}$, $N$, $M_Y$, and $M_\\text{IDP}$. \n:::\n\n- $h_Y$ is the heritability of $Y$\n- $h_\\text{IDP}$\n- $N$, is the sample size\n- $M_Y$ is the number of causal variants for Y\n- $M_\\text{IDP}$ is the number of causal variants for the IDP\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressMessages(library(tidyverse))\nsuppressMessages(library(glue))\n\nPRE = \"/Users/haekyungim/Library/CloudStorage/Box-Box/LargeFiles/imlab-data/data-Github/web-data\"\nSLUG=\"inflation-brainxcan\" ## copy the slug from the header\nbDATE='2023-04-07' ## copy the date from the blog's header here\nDATA = glue(\"{PRE}/{bDATE}-{SLUG}\")\nif(!file.exists(DATA)) system(glue::glue(\"mkdir {DATA}\"))\nWORK=DATA\n##system(glue(\"open {DATA}\")) ## this will open the folder \n```\n:::\n\n\n## Load and Define Functions\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressMessages(devtools::source_gist(\"115403f16bec0a0e871f3616d552ce9b\") ) ## load fn_ratxcan, fast regression and other convenience functions to correlate subsets of columns of two matrices\nsuppressMessages(devtools::source_gist(\"38431b74c6c0bf90c12f\") ) ## load qqunif\n\n\nmy_trace = function(mat) if(nrow(mat)==ncol(mat)) sum(diag(mat)) else error(\"matrix is not diagonal\")\nqqR2 <- function(corvec,nn,pad_neg_with_0 = FALSE,...)\n{\n## nn is the sample size, number of individuals used to compute correlation.\n## needs correlation vector as input.\n## nullcorvec generates a random sample from correlation distributions, under the null hypothesis of 0 correlation using Fisher's approximation.\n  if(pad_neg_with_0) corvec[corvec < 0 | is.na(corvec) ]=0\n  mm <- length(corvec)\n  nullcorvec = tanh(rnorm(mm)/sqrt(nn-3)) ## null correlation vector\n  qqplot(nullcorvec^2,corvec^2,...); abline(0,1); grid()\n}\n\nqqR <- function(corvec,nn,...)\n{\n## nn is the sample size, number of individuals used to compute correlation.\n## needs correlation vector as input.\n## nullcorvec generates a random sample from correlation distributions, under the null hypothesis of 0 correlation using Fisher's approximation.\n  mm <- length(corvec)\n  nullcorvec = tanh(rnorm(mm)/sqrt(nn-3)) ## null correlation vector\n  qqplot(nullcorvec,corvec,...); abline(0,1); grid()\n}\n\n## calculate p-value from correlation\ncor2zscore = function(cc,nn) \n{\n  zz = atanh(cc) * sqrt(nn-3)\n}\n\ncor2pval = function(cc,nn) \n{\n  zz=cor2zscore(cc,nn)\n  pnorm(-abs(zz))*2\n}\n\ncor2chi2 = function(cc,nn)\n{\n  cor2zscore(cc,nn)^2\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsimulate_study = function(nsam,msnp,nsim,midp)\n{\n  ## simulate Xmat (nsam x msnp)\n  Xmat = matrix(rbinom(nsam*msnp, 2, 0.4), nsam, msnp)\n\n  ## calculate GRM or LD matrix depending on min(nsam, msnp) and trrtr\n  R = scale(Xmat) ## QUESTION: DO I NEED TO SCALE ACROSS SAMPLES AND ACROSS SNPS?\n  if(nsam >  msnp) \n  {\n    R = t(R)\n    MM = nsam\n  } else MM = msnp\n  R = ( R %*% t(R) ) / MM\n  trrtr = my_trace( t(R) %*% R ) / my_trace(R)^2\n  \n  ## simulate IDPmat (nsam x mipd) \n  gammamat = matrix(rnorm(msnp * midp),msnp, midp)\n  epsimat2 = matrix(rnorm(nsam * midp),nsam, midp)\n  epsimat2 = scale(epsimat2)\n  epsimat2 = sweep(epsimat2, MARGIN=2, sqrt(1 - h2IDP), FUN=\"*\" )\n  gIDPmat = Xmat %*% gammamat\n  gIDPmat = scale(gIDPmat) \n  gIDPmat = sweep(gIDPmat, MARGIN=2, sqrt(h2IDP), FUN=\"*\" )\n  IDPmat = gIDPmat + epsimat2\n  \n  ## simulate Ymat (nsam x nsim) indep of IDPs\n  betamat = matrix(rnorm(msnp*nsim),msnp, nsim)\n  epsimat = matrix(rnorm(nsam*nsim),nsam, nsim)\n  epsimat = scale(epsimat) * sqrt(1 - h2Y)\n  gYmat = Xmat %*% betamat\n  gYmat = scale(gYmat) * sqrt(h2Y)\n  Ymat = gYmat + epsimat\n  \n  ## calc cor\n    ## scale Ymat & IDPmat\n  Ymat = scale(Ymat)\n  IDPmat = scale(IDPmat)\n    ## multiply t(Ymat) %*% IDPmat\n  cormat = t(Ymat) %*% IDPmat\n  cormat = cormat / nsam\n\n  ## calc varchi2\n  chi2mat = cor2chi2(cormat,nn=nsam)\n  varchi2 = apply(chi2mat,2,mean)\n\n  ## build result list\n  res = list()\n  res$varchi2 = varchi2\n  res$trrtr = trrtr\n  res\n}\n```\n:::\n\n\n## define parameters for simulation multiple comb of nsam and msnp\n\n::: {.cell}\n\n```{.r .cell-code}\nnsam = 10000\nnsim = 150\nmidp = 100\nmsnp = 1000\n\nh2Y = 0.5\nh2IDP = 0.1 + runif(midp) * 0.8\n\nnsamlist = c(100,1000,5000,10000); num_nsam=length(nsamlist)\nmsnplist = c(99,999,4999); num_msnp=length(msnplist)\n```\n:::\n\n\n## perform simulation\n\n::: {.cell}\n\n```{.r .cell-code}\nvarchi2mat = array(NA, dim=c(num_nsam, num_msnp, midp) )\ntrrtrmat = matrix(NA,num_nsam, num_msnp)\n\nfor(ii in 1:num_nsam)\n{\n  for(jj in 1:num_msnp)\n  {\n    res=list()\n    print(ii)\n    print(jj)\n    print(nsamlist[ii])\n    print(msnplist[jj])\n    res = simulate_study(nsam=nsamlist[ii],msnplist[jj],nsim,midp)\n    varchi2mat[ii,jj,] = res$varchi2\n    trrtrmat[ii,jj] = res$trrtr\n  }\n}\n##saveRDS(varchi2mat,glue(\"{DATA}/varchi2mat.RDS\"))\n```\n:::\n\n\n- [ ] TODO %%HERE read varchi2mat and analyze the dependence on h2, nsam, and msnp\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvarchi2mat = readRDS(glue(\"{DATA}/varchi2mat.RDS\"))\n\nvarchi2 = varchi2mat[1,2,]\n\nrangoy = range(c(0,varchi2-1))\nplot(h2IDP,varchi2-1,ylim=rangoy, xlim=c(0,1)); grid()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\nprint(\"intercept should be close to 1 and slope proportional to nsam\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"intercept should be close to 1 and slope proportional to nsam\"\n```\n:::\n\n```{.r .cell-code}\nsummary(lm(varchi2 ~ h2IDP))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = varchi2 ~ h2IDP)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.20139 -0.08423 -0.01282  0.07831  0.33049 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.95251    0.02318  41.100   <2e-16 ***\nh2IDP        0.09522    0.04602   2.069   0.0412 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1056 on 98 degrees of freedom\nMultiple R-squared:  0.04186,\tAdjusted R-squared:  0.03208 \nF-statistic: 4.281 on 1 and 98 DF,  p-value: 0.04117\n```\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}