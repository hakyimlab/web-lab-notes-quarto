{
  "hash": "d6f82c3ea166138344151cbb616d9ce6",
  "result": {
    "markdown": "---\ntitle: Attenuation bias in PrediXcan\nauthor: Haky Im\ndate: 2023-07-03\neditor_options: \n  chunk_output_type: console\n---\n\n\n::: {.callout-tip}\n## Summary\nUncertainty in predicted expression causes attenuation bias, and reduced significance of the association. Hence significance is underestimated.\n:::\n\nPrediXcan correlates genetically predicted expression levels with the phenotype to identify potentially causal genes. Let us assume that the phenotype $Y$ is a linear function of the genetic component of gene expression $T_g$:\n\n$$ Y = \\beta \\cdot T_g + \\epsilon_Y$$ \nAnd that the genetic component of gene expression has the form\n\n$$ T_g = \\sum_k \\omega_k \\cdot X_k$$\nIn practice, we don't have the exact value of $T_g$ but a noisy proxy for it: \n\n$$\\tilde{T_g} = T_g + \\epsilon_T$$\n\nSo what is the effect of using this noisy version of the genetic component of gene expression?\n\nWhat we want to estimate is \n\n$$\\hat{\\beta} = \\frac{T_g' \\cdot Y}{T_g' \\cdot T_g}$$\n\n\nInstead, we get\n\n\\begin{align}\n\\tilde{\\beta} & = \\frac{\\tilde{T_g}' \\cdot Y}{\\tilde{T_g}' \\cdot \\tilde{T_g}} \\\\\n              & = \\frac{(T_g + \\epsilon_T)' \\cdot Y}{\\tilde{T_g}' \\cdot \\tilde{T_g}} \\\\\n              & =  \\frac{T_g' \\cdot Y}{T_g' \\cdot T_g} \\cdot \\frac{T_g'\\cdot T_g}{\\tilde{T_g}' \\cdot \\tilde{T_g}} ~ + ~  \\frac{\\epsilon_T' \\cdot Y}{\\tilde{T_g}' \\cdot \\tilde{T_g}} \\\\\n              & = \\hat{\\beta} \\cdot \\frac{(T_g'\\cdot T_g)}{\\tilde{T_g}' \\cdot \\tilde{T_g}} ~ + ~  \\frac{\\epsilon_T' \\cdot Y}{\\tilde{T_g}' \\cdot \\tilde{T_g}} \\\\\n              & = \\hat{\\beta} \\cdot \\frac{(T_g'\\cdot T_g)}{\\tilde{T_g}' \\cdot   \\tilde{T_g}} ~ + ~   \\frac{\\epsilon_T' \\cdot Y}{\\tilde{T_g}' \\cdot \\tilde{T_g}}\\\\\n              & \\approx \\hat{\\beta} \\cdot \\frac{(T_g'\\cdot T_g)}{\\tilde{T_g}' \\cdot   \\tilde{T_g}}\n\\end{align}\n\n\nThe sample variance of $\\tilde{T_g}$ is\n\\begin{align}\n\\tilde{T_g}' \\cdot \\tilde{T_g} &= T_g' \\cdot T_g  + 2 \\cdot T_g' \\cdot \\epsilon_T + \\epsilon_T' \\cdot \\epsilon_T \\\\\n& \\approx T_g' \\cdot T_g   + \\epsilon_T' \\cdot \\epsilon_T \\\\\n& \\approx T_g' \\cdot T_g   + n \\text{ var}(\\epsilon_T) \\\\\n\\end{align}\n\n\nPutting together $\\tilde{\\beta}$ and $\\tilde{T_g}' \\cdot \\tilde{T_g}$ equations we get\n\n\\begin{align}\n \\tilde{\\beta} \n    & \\approx \\hat{\\beta} \\cdot \\frac{T_g'\\cdot T_g}{\\tilde{T_g}' \\cdot   \\tilde{T_g}} \\\\\n    & \\approx  \\hat{\\beta} \\cdot \\frac{T_g' \\cdot T_g}{T_g' \\cdot T_g   + \\text{var}(\\epsilon_T)}\\\\\n    & = \\hat{\\beta} \\cdot \\frac{1}{1 + \\text{var}(\\epsilon_T) / T_g' \\cdot T_g }\n\\end{align} \n\nTherefore  \n\\begin{align}\n     |\\tilde{\\beta}|& < |\\hat{\\beta}| + o_p(1) ~~~~~~~~~~~~\\text{if var}(\\epsilon_T) > 0 \n\\end{align}\n \nOne can also show that the standard error of $\\tilde\\beta$ is \n\n[See derivation here](https://econ.lse.ac.uk/staff/spischke/ec524/Merr_new.pdf)\n or [downloaded here in box](https://uchicago.box.com/s/iacrfxr9zxncwi7mwji8hcy8jj960ue9) where it is shown more rigurously using plim rather tha approx signs, that the estimated coefficient $\\beta$ with error in the independent variable is underestimated and that the t-statistics is also underestimated, i.e. less significant than the association should be.\n \n## illustration of attenuation by simulation\n\n::: {.cell}\n\n```{.r .cell-code}\nnsim = 100\n\nbeta = 0.5\nnsam = 98\n\nepsiY = rnorm(nsam,mean=0,sd=1)\nepsiT = rnorm(nsam,mean=0,sd=1)\nTsim = rnorm(nsam)\nYsim = beta * Tsim + epsiY\nTtilde = Tsim + epsiT\n\nfit_tilde = summary(lm(Ysim ~ Ttilde))\nfit_sim = summary(lm(Ysim ~ Tsim))\n\npvec_tilde=rep(NA,nsim)\ntvec_tilde=rep(NA,nsim)\nbetavec_tilde = rep(NA,nsim)\n\npvec_hat=rep(NA,nsim)\ntvec_hat=rep(NA,nsim)\nbetavec_hat = rep(NA,nsim)\n\nfor(ss in 1:nsim)\n{\nepsiY = rnorm(nsam,mean=0,sd=1)\nepsiT = rnorm(nsam,mean=0,sd=1)\nTsim = rnorm(nsam)\nYsim = beta * Tsim + epsiY\nTtilde = Tsim + epsiT\n\ncoef_tilde = coef(summary(lm(Ysim ~ Ttilde)))\ncoef_hat = coef(summary(lm(Ysim ~ Tsim)))\n\npvec_tilde[ss] = coef_tilde[2,\"Pr(>|t|)\"]\ntvec_tilde[ss] = coef_tilde[2,\"t value\"]\nbetavec_tilde[ss] = coef_tilde[2,\"Estimate\"]\n\npvec_hat[ss] = coef_hat[2,\"Pr(>|t|)\"]\ntvec_hat[ss] = coef_hat[2,\"t value\"]\nbetavec_hat[ss] = coef_hat[2,\"Estimate\"]\n}\n\nrango=range(-log10(pvec_hat),-log10(pvec_tilde))\nplot(-log10(pvec_hat),-log10(pvec_tilde),xlim=rango,ylim=rango); abline(0,1); title(\"less significant with error in variable\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n\n```{.r .cell-code}\nrango=range(tvec_hat,tvec_tilde)\nplot(tvec_hat,tvec_tilde,xlim=rango,ylim=rango); abline(0,1); title(\"t stat is underestimated; less significant with error in variable\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-2.png){width=672}\n:::\n\n```{.r .cell-code}\nrango=range(betavec_hat,betavec_tilde)\nplot(betavec_hat,betavec_tilde,xlim=rango,ylim=rango); abline(0,1);  title(\"regression coeff is underestimated\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-3.png){width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}