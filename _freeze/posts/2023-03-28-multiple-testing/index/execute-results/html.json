{
  "hash": "8524043fe4bd8631a7a24eec08e1f3f0",
  "result": {
    "markdown": "---\ntitle: \"Multiple Testing Vignette\"\nauthor: \"Haky Im\"\ndate: \"2023-03-28\"\ncategories: [vignette]\nformat:\n  html:\n    code-fold: false\n    code-summary: \"Show the code\"\neditor_options: \n  chunk_output_type: console\n---\n\n\n## Learning objectives\n\n- build intuition about p-values when multiple testing is performed via simulations \n- recognize the need for multiple testing correction\n- present methods to correct for multiple testing\n  - Bonferroni correction\n  - FDR (false discovery rate)\n\n## Why do we need multiple testing correction\n\n![xkcd image for significance](https://imgs.xkcd.com/comics/significant.png)\n\n## What do p-values look like under the null and alternative?\n\n### Simulate vectors X, Yalt=$X\\cdot \\beta + \\epsilon$ and Ynull independent of X\n\nWe start defining some parameters for the simulations. The need for these will become obvious later.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## set seed to make simulations reproducible\n## set.seed(20210108)\n\n## let's start with some parameter definitions\nnsamp = 100\nbeta = 2\nh2 = 0.1\nsig2X = h2\nsig2epsi = (1 - sig2X) * beta^2\nsigX = sqrt(sig2X)\nsigepsi = sqrt(sig2epsi)\n```\n:::\n\n\nNext, we simulate a vectors X and $\\epsilon$, and Ynull, all normally distributed\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX = rnorm(nsamp,mean=0, sd= sigX)\nepsi = rnorm(nsamp,mean=0, sd=sigepsi)\n## generate Ynull (X has no effect on Ynull)\nYnull = rnorm(nsamp, mean=0, sd=beta)\n```\n:::\n\n\nCalculate Yalt = X * beta + epsi\n\n\n::: {.cell}\n\n```{.r .cell-code}\nYalt = X * beta + epsi\n```\n:::\n\n\nVisualize Yalt vs X\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(X, Yalt, main=\"Yalt vs X\"); grid()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nVisualize Ynull vs X\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(X, Ynull, main=\"Ynull vs X\");grid()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nTest association between Ynull and X\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(Ynull ~ X))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Ynull ~ X)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.8431 -1.3431 -0.2234  1.2499  5.8569 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   0.1614     0.2046   0.789    0.432\nX            -0.2765     0.6653  -0.416    0.679\n\nResidual standard error: 2.039 on 98 degrees of freedom\nMultiple R-squared:  0.00176,\tAdjusted R-squared:  -0.008426 \nF-statistic: 0.1728 on 1 and 98 DF,  p-value: 0.6786\n```\n:::\n:::\n\n\n- [ ] what's the p-value of the association?\n\n- [ ] is the p-value significant at 5% significance leve?\n\nNext, test the association between Yalt and X\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(Yalt ~ X))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Yalt ~ X)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.9610 -1.3250  0.0524  1.6622  4.2743 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)  -0.2102     0.1976  -1.064  0.29004   \nX             1.8297     0.6424   2.848  0.00536 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.969 on 98 degrees of freedom\nMultiple R-squared:  0.07645,\tAdjusted R-squared:  0.06703 \nF-statistic: 8.113 on 1 and 98 DF,  p-value: 0.005357\n```\n:::\n:::\n\n\n\n- [ ] what's the p-value of the association?\n\n- [ ] is the p-value significant at 5% significance level?\n\n## Calculate the empirical distribution of p-values \n\nTo calculate the empirical distribution of p-values under the null and alternatives we will simulate X, Yalt, Ynull for 10,000 times.\n\n### Define a convenience function fastlm, will do linear regression much faster\n\nWe want to run 10,000 times this same regression, so here we define a function `fastlm` that will get us the p-values and regression coefficients.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfastlm = function(xx,yy)\n{\n  ## compute betahat (regression coef) and pvalue with Ftest\n  ## for now it does not take covariates\n  \n  df1 = 2\n  df0 = 1\n  ind = !is.na(xx) & !is.na(yy)\n  xx = xx[ind]\n  yy = yy[ind]\n  n = sum(ind)\n  xbar = mean(xx)\n  ybar = mean(yy)\n  xx = xx - xbar\n  yy = yy - ybar\n  \n  SXX = sum( xx^2 )\n  SYY = sum( yy^2 )\n  SXY = sum( xx * yy )\n  \n  betahat = SXY / SXX\n  \n  RSS1 = sum( ( yy - xx * betahat )^2 )\n  RSS0 = SYY\n  \n  fstat = ( ( RSS0 - RSS1 ) / ( df1 - df0 ) )  / ( RSS1 / ( n - df1 ) )\n  pval = 1 - pf(fstat, df1 = ( df1 - df0 ), df2 = ( n - df1 ))\n  res = list(betahat = betahat, pval = pval)\n  \n  return(res)\n}\n```\n:::\n\n\n### Simulate vectors X, Ynull, Yalt 10,000 times\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnsim = 10000\n## simulate normally distributed X and epsi\nXmat = matrix(rnorm(nsim * nsamp,mean=0, sd= sigX), nsamp, nsim)\nepsimat = matrix(rnorm(nsim * nsamp,mean=0, sd=sigepsi), nsamp, nsim)\n\n## generate Yalt (X has an effect on Yalt)\nYmat_alt = Xmat * beta + epsimat\n\n## generate Ynull (X has no effect on Ynull)\nYmat_null = matrix(rnorm(nsim * nsamp, mean=0, sd=beta), nsamp, nsim)\n\n## let's look at the dimensions of the simulated matrices\n\ndim(Ymat_null)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]   100 10000\n```\n:::\n\n```{.r .cell-code}\ndim(Ymat_alt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]   100 10000\n```\n:::\n:::\n\n\nNow we have 10000 independent simulations of X, Ynull, and Yalt\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## give them names so that we can refer to them later more easily\ncolnames(Ymat_null) = paste0(\"c\",1:ncol(Ymat_null))\ncolnames(Ymat_alt) = colnames(Ymat_null)\n```\n:::\n\n\n> To calculate p-values under the null run 10,000 linear regressions using X and Ynull\n\n\n::: {.cell}\n\n```{.r .cell-code}\npvec_null = rep(NA,nsim)\nbvec_null = rep(NA,nsim)\n\nfor(ss in 1:nsim)\n{\n  fit = fastlm(Xmat[,ss], Ymat_null[,ss])\n  pvec_null[ss] = fit$pval  \n  bvec_null[ss] = fit$betahat\n}\n\nsummary(pvec_null)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n0.0002453 0.2469528 0.4923302 0.4975967 0.7537629 0.9999578 \n```\n:::\n\n```{.r .cell-code}\nhist(pvec_null,xlab=\"p-value\",main=\"Histogram of p-values under Null\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n- [ ] how many simulations under the null yield p-value below 0.05? What percentage is that?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(pvec_null<0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 523\n```\n:::\n\n```{.r .cell-code}\nmean(pvec_null<0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0523\n```\n:::\n:::\n\n\n- [ ] how many simulations under the null yield p-value < 0.20?\n\n- [ ] what do you think the proportion of simulations with p-values < $\\alpha$ ($\\alpha$ between 0 and 1) will be roughly?\n\n- [ ] Why do we need to use more stringent significance level when we test many times?\n\n## Bonferroni correction\n\nUse as the new threshold the original one divided by the number of tests. So typically\n\n$$\\frac{0.05}{\\text{total number of tests}}$$\n\n- [ ] what's the Bonferroni threshold for significance in this simulation?\n\n- [ ] how many did we find?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nBF_thres = 0.05/nsim\n## Bonferroni significance threshold\nprint(BF_thres) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5e-06\n```\n:::\n\n```{.r .cell-code}\n## number of Bonferroni significant associations\nsum(pvec_null<BF_thres)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n\n```{.r .cell-code}\n## proportion of Bonferroni significant associations\nmean(pvec_null<BF_thres)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n\n\n## Mix of Ynull and Yalt\n\nLet's see what happens when we add a bunch of true associations in the matrix of null associations\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprop_alt=0.20 ## define proportion of alternative Ys in the mixture\nselectvec = rbinom(nsim,1,prop_alt)\nnames(selectvec) = colnames(Ymat_alt)\nselectvec[1:10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n c1  c2  c3  c4  c5  c6  c7  c8  c9 c10 \n  0   0   0   0   0   0   0   0   0   0 \n```\n:::\n\n```{.r .cell-code}\nYmat_mix = sweep(Ymat_alt,2,selectvec,FUN='*') + sweep(Ymat_null,2,1-selectvec,FUN='*')\n```\n:::\n\n\n<!-- Ymat_mix should have Yalt for columns that have 1's in selectvec and Ynull where selectvec==0. Let's double check that. -->\n\n<!-- ```{r} -->\n<!-- print(head(Ymat_mix[,1:10]),2) ## use 2 decimals -->\n<!-- print(selectvec[1:10]) -->\n<!-- print(\"subtract Ymat_alt\") -->\n<!-- print(head(Ymat_mix[,1:10] - Ymat_alt[,1:10]),2) -->\n<!-- print(\"subtract Ymat_null\") -->\n<!-- print(head(Ymat_mix[,1:10] - Ymat_null[,1:10]),2) -->\n<!-- ## Q: how many columns have true effect and how many have null effects -->\n<!-- sum(selectvec) -->\n<!-- mean(selectvec) -->\n<!-- ``` -->\n\nRun linear regression for all 10,000 phenotypes in the mix of true and false associations, Ymat_mix\n\n::: {.cell}\n\n```{.r .cell-code}\npvec_mix = rep(NA,nsim)\nbvec_mix = rep(NA,nsim)\nfor(ss in 1:nsim)\n{\n  fit = fastlm(Xmat[,ss], Ymat_mix[,ss])\n  pvec_mix[ss] = fit$pval  \n  bvec_mix[ss] = fit$betahat\n}\nsummary(pvec_mix)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.08125 0.37643 0.40485 0.68693 0.99988 \n```\n:::\n\n```{.r .cell-code}\nhist(pvec_mix,xlab=\"p-value\",main=\"Histogram of p-values under mixture of null and alt\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\nm_signif = sum(pvec_mix < 0.05) ## observed number of significant associations\nm_expected = 0.05*nsim ## expected number of significant associations under the worst case scenario, where all features belong to the null \nm_signif\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2191\n```\n:::\n\n```{.r .cell-code}\nm_expected\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 500\n```\n:::\n:::\n\n\n**Under the null, we were expecting 500 significant columns by chance but got 2191**\n\nQ: how can we estimate the proportion of true positives?\n\nWe got 1691 extra columns, so it's reasonable to expect that the extra significant results come from the alternative distribution (Yalt). So \n$$\\frac{\\text{observed number of significant} - \\text{expected number of significant}}{\\text{observed number of significant}}$$\nshould be a good estimate of the true discovery rate. \nFalse discovery rate is defined as 1 - the true discovery rate.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthres = 0.05\nFDR = sum((pvec_mix<thres & selectvec==0)) / sum(pvec_mix<thres)\n## proportion of null columns that are significant among all significant\nFDR\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1866728\n```\n:::\n:::\n\n**If we use a p-value threshold of 0.05, 81.33 percent of the signficant columns are true discoveries. ** In this case, we know which ones are true or false associations because we decided using the `selectvec` vectors which simulated Y would be a function of X or unrelated to X.\n\n- [ ] what's the proportion of false discoveries if we use a significance level of 0.01\n\n- [ ] what's the proportion of false discoveries if we use Bonferroni correction as the significance level? \n\n- [ ] What's the proportion of missed signals, proportion of true associations that have p-values greater than the Bonferroni threshold?\n\n## Common approaches to control type I errors\nAssuming we are testing $m$ hypothesis, let's define the following terms for the different errors.\n\n|          | Called Significant | Called not significant    | Total |\n| -----    |:------------------:|:-------------------------:|:------|\n|**Null true** | $F$                  | $m_0 - F$                  | $m_0$ |\n|**Alt true**  | $T$                  | $m_1 - T$                | $m_1$ |\n| **Total** | $S$                  | $m - S$ | $m$|\n\n- Bonferroni correction assures that the **FWER** (Familywise error rate) \n$P(F \\ge 1)$ is below the acceptable type I error, typically 0.05. \n$$P(F \\ge 1) < \\alpha. $$\nWe achieve that by requiring that for each test $$p<\\alpha/\\text{# tests}.$$ This can be too stringent and lead to miss real signals.\n- **pFDR** (positive false discovery rate) $$E\\left(\\frac{F}{S} \\rvert S>0\\right)$$\n- **qvalue** is the minimum false discovery rate attainable when the feature (SNP) is called significant\n\n\n## Table of null or alternative vs. significant or not significant\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncount_table = t(table(pvec_mix>0.05, selectvec))\ncolnames(count_table) = c(\"Called significant\", \"Called not significant\")\nrownames(count_table) = c(\"Null true\", \"Alt true\")\nknitr::kable(count_table)\n```\n\n::: {.cell-output-display}\n|          | Called significant| Called not significant|\n|:---------|------------------:|----------------------:|\n|Null true |                409|                   7611|\n|Alt true  |               1782|                    198|\n:::\n:::\n\n\n\n\nLet's calculate the qvalue\n\n## Use qvalue package to calculate FDR and \n\nLet's check whether small qvalues correspond to true associations (i.e. the phenotype was generated under the alternative distribution)\n\n::: {.cell}\n\n```{.r .cell-code}\n## install qvalue if not available.\nif(F) ## I set it to F now because I already installed the qvalue package\n{if (!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"qvalue\")\n}\n\n## calculate qvalue using the qvalue function, which returns a list of values, we select the qvalue vector, which assigns the false discovery rate if the threshold for significance was the p-value of the same simulation vector\n\nqres_mix = qvalue::qvalue(pvec_mix)\nqvec_mix = qres_mix$qvalue\n\nqres_null = qvalue::qvalue(pvec_null)\nqvec_null = qres_null$qvalue\n\nboxplot(qvec_mix~selectvec)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n\n```{.r .cell-code}\n##plot(qvec_mix,col=selectvec*2 + 1, pch=selectvec + 1, lwd=selectvec*2 + 1) \n## using selectvec*2 + 1 as a quick way to get the vector to be 1 and 3 (1 is black 3 is green) instead of 1 and 2 (2 is read and can be difficult to read for color blind people)\n```\n:::\n\n\n\nPlot sorted qvalues and color by the selectvec status (true association status)\n\n::: {.cell}\n\n```{.r .cell-code}\nind=order(qvec_mix,decreasing=FALSE)\nplot(sort(qvec_mix),col=selectvec[ind]*2 + 1, pch=selectvec[ind] + 1, lwd=selectvec[ind]*2 + 1) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n\n```{.r .cell-code}\nsummary(qvec_mix) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n0.0000001 0.2605298 0.6035350 0.4948872 0.7344018 0.8018152 \n```\n:::\n:::\n\n\n- [ ] do small qvalues tend to be true?\n- [ ] interpret the figure\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## distribution of qvalues and pvalues by causal status\nboxplot(pvec_mix ~ selectvec, main='pvalue by causal status; 1=alt, 0=null')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n\n```{.r .cell-code}\nboxplot(qvec_mix ~ selectvec, main='qvalue by causal status; 1=alt, 0=null')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-2.png){width=672}\n:::\n:::\n\n\n- [ ] interpret these figures\n\n## How do qvalues and pvalues relate to each other?\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(pvec_null,qvec_null,main='qvalue vs pvalue for null')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(pvec_mix,qvec_mix,main='qvalue vs pvalue for mixture of null and alt')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-2.png){width=672}\n:::\n:::\n\n\n> q-values are monotonic functions of p-values\n\n- [ ] what's the smallest qvalue when all simulations are from the null?\n- [ ] what's the smallest qvalue when all simulations are from the mixture?\n\n\n## pi0 and pi1\npi0 is the proportion of null hypothesis which can be estimated using the qvalue package\n1 - pi1 is the proportion of true positive associations. This is a useful parameter as we will see in later classes.\n\n::: {.cell}\n\n```{.r .cell-code}\nqres_null$pi0\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9846734\n```\n:::\n\n```{.r .cell-code}\nqres_mix$pi0\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8019101\n```\n:::\n:::\n\n\n- [ ] how many true positive proportion did you expect given the simulations we performed?\n\n\n## References\n\nStorey, John D., and Robert Tibshirani. 2003. “Statistical Significance for Genomewide Studies.” Proceedings of the National Academy of Sciences 100 (16): 9440–45.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}